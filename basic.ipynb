{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gLyh9qOCrJH",
        "colab_type": "text"
      },
      "source": [
        "###**線形代数要点**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fcWIHyw4S9H",
        "colab_type": "text"
      },
      "source": [
        "・線形代数とは普通の数であるスカラーに向きを加えたベクトルやスカラーを表にした行列を扱う。  \n",
        "・加算、乗算、転置、逆行列によるデータの変換を行うことができる。  \n",
        "・また固有値分解で行列の累乗の計算が容易にすることができたり、\n",
        "特異値分解でデータの性質を維持してデータ量を減らすなどすることができる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_znPkz4Pl5p",
        "colab_type": "text"
      },
      "source": [
        "###**確率要点**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xavlu8v5PruH",
        "colab_type": "text"
      },
      "source": [
        "・確率には発生する頻度を表す頻度確率と信念の度合いを表すベイズ確率がある。  \n",
        "・ある事象Xとある事象Yが同時に発生する確率=事象Xの発生する確率＊ある事象Yに等しい。→同時確率  \n",
        "・ある事象X=xが与えられた下で，Y=yとなる確率=ある事象Xとある事象Yが同時に発生する確率/事象Xの発生する確率→条件付き確率  \n",
        "・ベイズ則は同時確率と条件確率の組み合わせ。  \n",
        "・確率変数はX枚ののコインを投げた時に表になったコインの枚数など事象に結び付けられた数値。  \n",
        "・期待値は確率変数の平均値（各確率変数＊確率の合計）  \n",
        "・分散はデータの散らばり具合を表す。（実データ-期待値）^2の合計  \n",
        "・共分散は２つのデータの傾向の違いを表す。（Xの実データ-Xの期待値）*(Yの実データ-Yの期待値)  \n",
        "・ベルヌーイ分布はコイントスのように２つの事象の確率の分布を表す。  \n",
        "・マルチヌーイはサイコロのように２より大きい事象の確率の分布を表す。  \n",
        "・二項分布はベルヌーイ分布を複数回施行した時の確率分布である。\n",
        "・ガウス分布は釣鐘型の連続した分布"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGoNc5fVLH_6",
        "colab_type": "text"
      },
      "source": [
        "###**情報理論要点**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_uVyimoLOOW",
        "colab_type": "text"
      },
      "source": [
        "・１から２になる場合と１０から１１になる場合ではどちらも１増えているが増えている比率が違う。後者の方が情報量が多いという。  \n",
        "・自己情報量は確率pに対してI (p) = -log pで表す。底数が２の場合bit、ネイピア数の場合はnatが単位となる。  \n",
        "・シャノンエントロピーは自己情報量の期待値であり、各確率p*pの自己情報量の合計値である  \n",
        "・カルバックライブラーダイバージェンスは２つの確率分布P,Qの違いを表す  \n",
        "logq-logpで計算できる。（Qは見積もっていた確率、Pは実際の確率など）\n",
        "・交差エントロピーはカルバックライブラーダイバージェンスのうちQについての自己情報量をPの分布で平均したものである。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34fcvXnJIAFZ",
        "colab_type": "text"
      },
      "source": [
        "###**線形回帰要点**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6U9RFx0IH6Q",
        "colab_type": "text"
      },
      "source": [
        "・教師あり学習の一つで回帰問題を解くための機械学習モデルの一つで\n",
        "目的変数（出力値）が説明変数（入力値）に対して線形なモデルを学習するものである  \n",
        "・線形回帰で訓練データを学習するときは予測値と実データの誤差を二乗した値の最小化（最小二乗法）や最尤法を行う\n",
        "・最小二乗法と最尤法の解は同じになる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12N9NBW_xP-W",
        "colab_type": "text"
      },
      "source": [
        "####ハンズオン\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/lreg1.png)\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/lreg2.png)\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/lreg3.png)\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/lreg4.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVK55qj0La4c",
        "colab_type": "text"
      },
      "source": [
        "###**非線形回帰要点**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqDAleqpLzbf",
        "colab_type": "text"
      },
      "source": [
        "・教師あり学習の一つで回帰問題を解くための機械学習モデルの一つであることは線形回帰と同様だが、目的変数（出力値）が説明変数（入力値）に対して非線形な関係性にあるデータを学習するものである  \n",
        "・回帰関数は線形回帰とは異なり基底関数と呼ばれる関数を扱う  \n",
        "・基底関数には多項式関数やガウス型基底関数を使うことが多い  \n",
        "・学習データで誤差が十分小さくならない未学習や学習データで誤差を小さくすることはできても\n",
        "予測するデータでは誤差が大きくなる過学習が発生することがある  \n",
        "・学習がうまくいかない時には適切なモデルを選択する他正則化を行う  \n",
        "・L2ノルム（リッジ正則化）でパラメータを0に近づけることができる\n",
        "・L1ノルム（ラッソ正則化）でいくつかのパラメータを0にすることができる（スパース）\n",
        "・データをいくつかに分割して学習用と検証用に分け学習する交差検証をすることが多い"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CDt4PxYyfX5",
        "colab_type": "text"
      },
      "source": [
        "####ハンズオン\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/nlreg1.png)\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/nlreg2.png)\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/nlreg3.png)\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/nlreg4.png)\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/nlreg5.png)\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/nlreg6.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwHTcNurdsD_",
        "colab_type": "text"
      },
      "source": [
        "###**ロジスティック回帰モデル要点**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLp9Zr5Gdx0C",
        "colab_type": "text"
      },
      "source": [
        "・ある入力（説明変数）がどのクラスに属するかを分類するための教師ありモデル  \n",
        "・目的変数は属するクラスを設定する  \n",
        "・重み＊入力値+バイアスにシグモイド関数を使うことで入力値がどのクラスに属する確率が高いかを予測する。  \n",
        "・最尤推定で重みを計算して推定する  \n",
        "・重みパラメータの勾配降下法で計算するが、全てのデータに対する和が必要なため実際には確率的勾配降下法（SGD）が用いられる  \n",
        "・予測結果は混同行列で評価する。評価方法はどのような予測をしたいかで使い分けが必要。\n",
        "・評価方法は正解率、適合率、再現率、F値（適合率と再現率の調和平均）などがある\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za_KoiCfJPtD",
        "colab_type": "text"
      },
      "source": [
        "####ハンズオン\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/log1.png)\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/log2.png)\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/log3.png)\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/log4.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS1gQ-NvlaSE",
        "colab_type": "text"
      },
      "source": [
        "###**主成分分析要点**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2hLzj9blemT",
        "colab_type": "text"
      },
      "source": [
        "・多変量データの持つ構造をより少数個の指標に圧縮するために使用する教師なしモデル  \n",
        "・分散共分散が最大となる射影軸を探索する。（固有値、固有ベクトル）  \n",
        "・分散の大きいものから第一主成分、第二主成分・・・第k主成分と呼ぶ\n",
        "・全ての主成分の分散の和は元のデータの分散と一致する  \n",
        "・各主成分の分散の全分散に対する割合を寄与率といい、1~k主成分までを合計したものを累積主成分という。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udwla2Gvo0id",
        "colab_type": "text"
      },
      "source": [
        "####ハンズオン\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/pca1.png)\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/pca2.png)\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/pca3.png)\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/pca4.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nluETNk76mbj",
        "colab_type": "text"
      },
      "source": [
        "###**k近傍法要点**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1P0oTwc7Y20",
        "colab_type": "text"
      },
      "source": [
        "・予測したいデータの近くにあるk個のデータが最も多く所属しているクラスを分類する教師なしモデル  \n",
        "・kの値を変えると予測したいデータの近くにあるデータのクラスの数が変わるので結果が変わる  \n",
        "・kを大きくすると決定境界がなめらかになる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOpKzrF7Ezec",
        "colab_type": "text"
      },
      "source": [
        "####ハンズオン\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/knn1.png)\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/knn2.png)\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/knn3.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBPWe4fj7rxB",
        "colab_type": "text"
      },
      "source": [
        "###**k-meansは対象外**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQbY6xua7x5u",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8V9jyGk9ZCR",
        "colab_type": "text"
      },
      "source": [
        "###**サポートベクターマシン(SVM)要点**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InrEMJ519eu4",
        "colab_type": "text"
      },
      "source": [
        "・与えられたデータを2クラスに分類するための教師ありモデル  \n",
        "・データがどこで分類される決定境界になる線形関数なのかを求める   \n",
        "・決定境界はいくつも存在するので、線形関数と一番近いデータの距離\n",
        "マージン）が最大となる線形関数がSVMで求める関数となる  \n",
        "・データの分布が非線形で分類できないときは非線形カーネルを用いることで分類することができる  \n",
        "・データに重なりがあり分類できないときはソフトマージンSVMで分類できる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yc-VoC91d8aN",
        "colab_type": "text"
      },
      "source": [
        "####ハンズオン\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/svm1.png)\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/svm2.png)\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/svm3.png)\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/svm4.png)\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/svm5.png)\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/svm6.png)\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/svm7.png)\n",
        "![代替テキスト](https://eshikaku.s3-us-west-2.amazonaws.com/svm8.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnxY-y1kIHBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}